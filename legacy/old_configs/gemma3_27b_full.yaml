model:
  name: google/gemma-3-27b-pt
  family: gemma3
  layer: 26
  dtype: bfloat16
  device_map: auto  # Spread across all 3 GPUs

slurm:
  gpus: 3
  cpus: 16
  mem_gb: 180
  time: "24:00:00"

steering:
  enabled_variants: [baseline, steered, mlp_gen]  # Skip mlp_mc (ineffective)

evaluation:
  preset: qa  # Use QA preset with few-shot examples

  judge:
    mode: zero_shot
    model: google/gemma-3-12b-it
    max_new_tokens: 128
    dtype: bfloat16
    device_map: auto  # Judge loads after main model is freed

  informativeness:
    enabled: true
    mode: zero_shot
    model: google/gemma-3-12b-it
    max_new_tokens: 128
    dtype: bfloat16
    device_map: auto

  semantic:
    enabled: true
    use_false_refs: true
