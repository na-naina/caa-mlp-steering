base: configs/gemma3_27b_it_full.yaml

model:
  name: google/gemma-3-27b-it  # Explicit override to prevent base.yaml override
  dtype: bfloat16  # Use native Gemma3 training precision (bf16 range: 10^38 vs fp16: 65,504)
  layer: 26  # Original extraction layer (reverted from 18)

steering:
  max_length: 384  # Shorter extraction context to reduce activation magnitude
  batch_size: 4  # Smaller extraction batches
  autocast_dtype: bfloat16  # Enable autocast to prevent Inf√ó0=NaN operations
